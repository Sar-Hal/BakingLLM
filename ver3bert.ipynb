{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BakingLLM - Structured Recipe Conversion System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\KIIT0001\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\beartype\\_util\\error\\utilerrwarn.py:67: BeartypeModuleUnimportableWarning: Ignoring module \"onnx\" importation exception:\n",
      "    ImportError: DLL load failed while importing onnx_cpp2py_export: A dynamic link library (DLL) initialization routine failed.\n",
      "  warn(message, cls)\n",
      "c:\\Users\\KIIT0001\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\beartype\\_util\\error\\utilerrwarn.py:67: BeartypeModuleUnimportableWarning: Ignoring module \"onnx\" importation exception:\n",
      "    ImportError: DLL load failed while importing onnx_cpp2py_export: A dynamic link library (DLL) initialization routine failed.\n",
      "  warn(message, cls)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\KIIT0001\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    DistilBertForTokenClassification,\n",
    "    pipeline,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n",
    "from pydantic import BaseModel\n",
    "from typing import List, Literal\n",
    "import google.generativeai as genai\n",
    "import json\n",
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "genai.configure(api_key=os.getenv(\"GEMINI_API_KEY\"))\n",
    "gemini_client = genai.GenerativeModel(\"gemini-2.0-flash\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FoodBERT Model Setup\n",
    "### Initialize model with food-specific weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae806e40e30740f3b7a141df8146e229",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\KIIT0001\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\KIIT0001\\.cache\\huggingface\\hub\\models--chambliss--distilbert-for-food-extraction. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fc298a0118b45dda8453f1861b35423",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/706 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2691c8b0130440569fc073161f5cb902",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a0d4bebac4448818cd4315d53494031",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\KIIT0001\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "485666154e6b42eabd5676920a23cf30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/261M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "FOODBERT_CHECKPOINT = \"chambliss/distilbert-for-food-extraction\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(FOODBERT_CHECKPOINT)\n",
    "model = DistilBertForTokenClassification.from_pretrained(FOODBERT_CHECKPOINT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define label mapping (Search Result 2, 8)\n",
    "LABEL_MAP = {\n",
    "    0: \"B-INGREDIENT\",\n",
    "    1: \"I-INGREDIENT\",\n",
    "    2: \"B-AMOUNT\",\n",
    "    3: \"I-AMOUNT\",\n",
    "    4: \"B-UNIT\",\n",
    "    5: \"I-UNIT\",\n",
    "    6: \"O\"\n",
    "}\n",
    "## Data Models\n",
    "class Ingredient(BaseModel):\n",
    "    name: str\n",
    "    amount: str\n",
    "    unit: str\n",
    "    type: Literal[\"dry\", \"liquid\"]\n",
    "\n",
    "class Recipe(BaseModel):\n",
    "    ingredients: List[Ingredient]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Enhanced Extraction Pipeline (Search Result 1, 6)\n",
    "def parse_entities(text: str) -> Recipe:\n",
    "    \"\"\"Convert model outputs to structured recipe format\"\"\"\n",
    "    ner_pipeline = pipeline(\n",
    "        \"token-classification\",\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        aggregation_strategy=\"simple\"\n",
    "    )\n",
    "    \n",
    "    entities = ner_pipeline(text)\n",
    "    ingredients = []\n",
    "    current = {\"name\": \"\", \"amount\": \"\", \"unit\": \"\"}\n",
    "    \n",
    "    for entity in entities:\n",
    "        token = text[entity[\"start\"]:entity[\"end\"]]\n",
    "        label = LABEL_MAP[entity[\"entity\"][-1]]\n",
    "        \n",
    "        if label == \"B-INGREDIENT\":\n",
    "            if current[\"name\"]:\n",
    "                ingredients.append(current)\n",
    "                current = {\"name\": \"\", \"amount\": \"\", \"unit\": \"\"}\n",
    "            current[\"name\"] = token\n",
    "        elif label == \"I-INGREDIENT\":\n",
    "            current[\"name\"] += \" \" + token\n",
    "        elif label.startswith(\"B-AMOUNT\"):\n",
    "            current[\"amount\"] = token\n",
    "        elif label.startswith(\"B-UNIT\"):\n",
    "            current[\"unit\"] = token\n",
    "    \n",
    "    # Add final ingredient and determine types\n",
    "    if current[\"name\"]:\n",
    "        ingredients.append(current)\n",
    "    \n",
    "    return Recipe(ingredients=[\n",
    "        Ingredient(\n",
    "            name=ing[\"name\"].strip(),\n",
    "            amount=ing[\"amount\"],\n",
    "            unit=ing[\"unit\"],\n",
    "            type=ingredient_type_lookup(ing[\"name\"])\n",
    "        ) for ing in ingredients\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ingredient Type Classifier (Search Result 5)\n",
    "INGREDIENT_TYPE_LOOKUP = {\n",
    "    # Dry ingredients\n",
    "    \"flour\": \"dry\", \"sugar\": \"dry\", \"baking powder\": \"dry\",\n",
    "    \"salt\": \"dry\", \"cocoa powder\": \"dry\", \"spices\": \"dry\",\n",
    "    \n",
    "    # Liquid ingredients\n",
    "    \"milk\": \"liquid\", \"water\": \"liquid\", \"oil\": \"liquid\",\n",
    "    \"vanilla extract\": \"liquid\", \"honey\": \"liquid\"\n",
    "}\n",
    "\n",
    "def ingredient_type_lookup(name: str) -> str:\n",
    "    \"\"\"Determine ingredient type using lookup table\"\"\"\n",
    "    lower_name = name.lower()\n",
    "    for key, value in INGREDIENT_TYPE_LOOKUP.items():\n",
    "        if key in lower_name:\n",
    "            return value\n",
    "    return \"dry\"  # Default assumption\n",
    "\n",
    "# %% [markdown]\n",
    "## Measurement Conversion Engine\n",
    "CONVERSION_PROMPT = \"\"\"... (keep your existing Gemini prompt) ...\"\"\"\n",
    "\n",
    "def convert_measurements(recipe: Recipe) -> dict:\n",
    "    \"\"\"Convert ingredients using Gemini API\"\"\"\n",
    "    ingredients_str = \", \".join(\n",
    "        f\"{i.amount} {i.unit} {i.name} ({i.type})\"\n",
    "        for i in recipe.ingredients\n",
    "    )\n",
    "    \n",
    "    response = gemini_client.generate_content(\n",
    "        CONVERSION_PROMPT + f\"\\n\\nConvert: {ingredients_str}\"\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        return json.loads(response.text)\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"Conversion failed, returning empty data\")\n",
    "        return {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'entity'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m recipe_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2 cups all-purpose flour, 1.5 cups granulated sugar, 3/4 cup whole milk\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Process pipeline\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m extracted \u001b[38;5;241m=\u001b[39m \u001b[43mparse_entities\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecipe_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtracted Ingredients:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(extracted\u001b[38;5;241m.\u001b[39mmodel_dump_json(indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m))\n",
      "Cell \u001b[1;32mIn[5], line 17\u001b[0m, in \u001b[0;36mparse_entities\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m entity \u001b[38;5;129;01min\u001b[39;00m entities:\n\u001b[0;32m     16\u001b[0m     token \u001b[38;5;241m=\u001b[39m text[entity[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart\u001b[39m\u001b[38;5;124m\"\u001b[39m]:entity[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[1;32m---> 17\u001b[0m     label \u001b[38;5;241m=\u001b[39m LABEL_MAP[\u001b[43mentity\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mentity\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]]\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m label \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mB-INGREDIENT\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     20\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m current[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "\u001b[1;31mKeyError\u001b[0m: 'entity'"
     ]
    }
   ],
   "source": [
    "## Main Execution Flow\n",
    "if __name__ == \"__main__\":\n",
    "    # Sample input\n",
    "    recipe_text = \"2 cups all-purpose flour, 1.5 cups granulated sugar, 3/4 cup whole milk\"\n",
    "    \n",
    "    # Process pipeline\n",
    "    extracted = parse_entities(recipe_text)\n",
    "    print(\"Extracted Ingredients:\")\n",
    "    print(extracted.model_dump_json(indent=2))\n",
    "    \n",
    "    conversions = convert_measurements(extracted)\n",
    "    print(\"\\nConverted Measurements:\")\n",
    "    print(json.dumps(conversions, indent=2))\n",
    "    \n",
    "    # Save output\n",
    "    with open(\"baking_conversions.json\", \"w\") as f:\n",
    "        json.dump(conversions, f, indent=2)\n",
    "    print(\"\\nSaved conversions to baking_conversions.json\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
