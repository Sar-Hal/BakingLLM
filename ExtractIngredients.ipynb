{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Extracting ingredients...\n",
      "‚ùå Failed extraction. Raw NER entities:\n",
      "[\n",
      "  {\n",
      "    \"entity_group\": \"FOOD\",\n",
      "    \"score\": 0.9750493764877319,\n",
      "    \"word\": \" Cookies\",\n",
      "    \"start\": 13,\n",
      "    \"end\": 20\n",
      "  },\n",
      "  {\n",
      "    \"entity_group\": \"FOOD\",\n",
      "    \"score\": 0.9996922016143799,\n",
      "    \"word\": \" all\",\n",
      "    \"start\": 39,\n",
      "    \"end\": 42\n",
      "  },\n",
      "  {\n",
      "    \"entity_group\": \"FOOD\",\n",
      "    \"score\": 0.9996534585952759,\n",
      "    \"word\": \"-\",\n",
      "    \"start\": 42,\n",
      "    \"end\": 43\n",
      "  },\n",
      "  {\n",
      "    \"entity_group\": \"FOOD\",\n",
      "    \"score\": 0.9945042133331299,\n",
      "    \"word\": \"purpose flour\",\n",
      "    \"start\": 43,\n",
      "    \"end\": 56\n",
      "  },\n",
      "  {\n",
      "    \"entity_group\": \"FOOD\",\n",
      "    \"score\": 0.9962606430053711,\n",
      "    \"word\": \" baking soda\",\n",
      "    \"start\": 74,\n",
      "    \"end\": 85\n",
      "  },\n",
      "  {\n",
      "    \"entity_group\": \"FOOD\",\n",
      "    \"score\": 0.9965425133705139,\n",
      "    \"word\": \" butter\",\n",
      "    \"start\": 107,\n",
      "    \"end\": 113\n",
      "  },\n",
      "  {\n",
      "    \"entity_group\": \"FOOD\",\n",
      "    \"score\": 0.9990413188934326,\n",
      "    \"word\": \" brown sugar\",\n",
      "    \"start\": 135,\n",
      "    \"end\": 146\n",
      "  },\n",
      "  {\n",
      "    \"entity_group\": \"FOOD\",\n",
      "    \"score\": 0.9995044469833374,\n",
      "    \"word\": \" chocolate chips\",\n",
      "    \"start\": 160,\n",
      "    \"end\": 175\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import google.generativeai as genai\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import re\n",
    "from fractions import Fraction\n",
    "import json\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "# Initialize models\n",
    "food_ner = pipeline(\n",
    "    \"token-classification\",\n",
    "    model=\"Dizex/InstaFoodRoBERTa-NER\",\n",
    "    aggregation_strategy=\"simple\",\n",
    "    device=-1\n",
    ")\n",
    "genai.configure(api_key=GEMINI_API_KEY)\n",
    "gemini = genai.GenerativeModel(\"gemini-2.0-flash\")\n",
    "\n",
    "def parse_quantity(qty_str):\n",
    "    try:\n",
    "        if ' ' in qty_str and '/' in qty_str:\n",
    "            whole, fraction = qty_str.split()\n",
    "            return float(whole) + float(Fraction(fraction))\n",
    "        return float(Fraction(qty_str))\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def extract_ingredients(text):\n",
    "    entities = food_ner(text)\n",
    "    ingredients = []\n",
    "    \n",
    "    # Merge hyphenated ingredients and list markers\n",
    "    merged_entities = []\n",
    "    buffer = []\n",
    "    \n",
    "    for entity in entities:\n",
    "        word = entity['word'].strip()\n",
    "        \n",
    "        if word == '-':\n",
    "            if buffer:\n",
    "                buffer[-1]['word'] += '-'\n",
    "        elif word.startswith('-'):\n",
    "            if buffer:\n",
    "                buffer[-1]['word'] += word\n",
    "            else:\n",
    "                entity['word'] = word[1:].strip()\n",
    "                buffer.append(entity)\n",
    "        else:\n",
    "            if buffer:\n",
    "                merged_entities.append({\n",
    "                    'entity_group': 'FOOD',\n",
    "                    'word': ' '.join([e['word'] for e in buffer]),\n",
    "                    'score': sum(e['score'] for e in buffer)/len(buffer),\n",
    "                    'start': buffer[0]['start'],\n",
    "                    'end': entity['end']\n",
    "                })\n",
    "                buffer = []\n",
    "            buffer.append(entity)\n",
    "    \n",
    "    # Process remaining buffer\n",
    "    if buffer:\n",
    "        merged_entities.append({\n",
    "            'entity_group': 'FOOD',\n",
    "            'word': ' '.join([e['word'] for e in buffer]),\n",
    "            'score': sum(e['score'] for e in buffer)/len(buffer),\n",
    "            'start': buffer[0]['start'],\n",
    "            'end': buffer[-1]['end']\n",
    "        })\n",
    "    \n",
    "    # Now process merged entities\n",
    "    for entity in merged_entities:\n",
    "        if entity['score'] < 0.9:  # Confidence threshold\n",
    "            continue\n",
    "            \n",
    "        # Enhanced pattern for recipe quantities\n",
    "        match = re.search(\n",
    "            r'(\\d+/\\d+|\\d+\\.\\d+|\\d+\\s\\d+/\\d+|\\d+)\\s*(cup|tbsp|tsp|oz|lb|teaspoon|tablespoon)s?\\s*(.*)',\n",
    "            entity['word'],\n",
    "            re.IGNORECASE\n",
    "        )\n",
    "        \n",
    "        if match:\n",
    "            qty, unit, ingredient = match.groups()\n",
    "            quantity = parse_quantity(qty)\n",
    "            if quantity and unit:\n",
    "                ingredients.append({\n",
    "                    \"ingredient\": ingredient.replace('-', ' ').strip().lower(),\n",
    "                    \"quantity\": quantity,\n",
    "                    \"unit\": unit.lower()\n",
    "                })\n",
    "    \n",
    "    return ingredients\n",
    "\n",
    "def process_phrase(entities, ingredients):\n",
    "    # Reconstruct full text with original spacing\n",
    "    full_text = \" \".join([e['word'].strip() for e in entities]).replace(\" - \", \"-\")\n",
    "    \n",
    "    # Enhanced pattern for recipe-style measurements\n",
    "    match = re.search(\n",
    "        r'(-?\\s*)?(\\d+/\\d+|\\d+\\.\\d+|\\d+\\s\\d+/\\d+|\\d+)\\s*(cup|tbsp|tsp|oz|lb|teaspoon|tablespoon)s?\\s*(.*)',\n",
    "        full_text,\n",
    "        re.IGNORECASE\n",
    "    )\n",
    "    \n",
    "    if match:\n",
    "        _, qty, unit, ingredient = match.groups()\n",
    "        quantity = parse_quantity(qty)\n",
    "        if quantity and unit:\n",
    "            ingredients.append({\n",
    "                \"ingredient\": ingredient.strip().lower(),\n",
    "                \"quantity\": quantity,\n",
    "                \"unit\": unit.lower()\n",
    "            })\n",
    "\n",
    "def convert_with_gemini(ingredients):\n",
    "    prompt = f\"\"\"Convert these baking measurements to grams. Return JSON format:\n",
    "    [{{\"ingredient\": \"...\", \"grams\": number, \"notes\": \"...\"}}]\n",
    "    \n",
    "    Rules:\n",
    "    1 cup flour = 125g (spooned & leveled)\n",
    "    1 cup sugar = 200g\n",
    "    1 cup butter = 227g\n",
    "    1 tbsp = 3 teaspoons\n",
    "    \n",
    "    Ingredients:\n",
    "    {json.dumps(ingredients, indent=2)}\"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = gemini.generate_content(prompt)\n",
    "        clean_response = response.text.replace('```json', '').replace('```', '').strip()\n",
    "        return json.loads(clean_response)\n",
    "    except Exception as e:\n",
    "        print(f\"Gemini Error: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def process_recipe(text):\n",
    "    print(\"üîç Extracting ingredients...\")\n",
    "    ingredients = extract_ingredients(text)\n",
    "    \n",
    "    if not ingredients:\n",
    "        print(\"‚ùå Failed extraction. Raw NER entities:\")\n",
    "        # Convert numpy floats to Python floats for JSON serialization\n",
    "        raw_entities = food_ner(text)\n",
    "        serializable_entities = [\n",
    "            {\n",
    "                \"entity_group\": e[\"entity_group\"],\n",
    "                \"score\": float(e[\"score\"]),  # Convert numpy float32 to Python float\n",
    "                \"word\": e[\"word\"],\n",
    "                \"start\": e[\"start\"],\n",
    "                \"end\": e[\"end\"]\n",
    "            }\n",
    "            for e in raw_entities\n",
    "        ]\n",
    "        print(json.dumps(serializable_entities, indent=2))\n",
    "        return\n",
    "    \n",
    "    # Rest of the code remains the same...\n",
    "\n",
    "# Test with your recipe\n",
    "if __name__ == \"__main__\":\n",
    "    recipe = \"\"\"\n",
    "    Classic Cookies:\n",
    "    - 2 1/4 cups all-purpose flour\n",
    "    - 1 teaspoon baking soda\n",
    "    - 1 cup unsalted butter\n",
    "    - 3/4 cup packed brown sugar\n",
    "    - 2 cups chocolate chips\n",
    "    \"\"\"\n",
    "    process_recipe(recipe)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
