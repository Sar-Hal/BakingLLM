{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0eb2134647624cb2ba3be1662974553a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.19k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\KIIT0001\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\KIIT0001\\.cache\\huggingface\\hub\\models--alexdseo--RecipeBERT. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "434c2584b6eb49d7b37db6544e8ed93b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "847991be03dd4b9f95da310b3b8af848",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "994228d9b7e5406bb2bfcb3f22848492",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76ae09a4af254c30b8c166093fd46f4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/664 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type bert to instantiate a model of type distilbert. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e2c441362dc4781991ca356d1854d8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at alexdseo/RecipeBERT and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.word_embeddings.weight', 'transformer.layer.0.attention.k_lin.bias', 'transformer.layer.0.attention.k_lin.weight', 'transformer.layer.0.attention.out_lin.bias', 'transformer.layer.0.attention.out_lin.weight', 'transformer.layer.0.attention.q_lin.bias', 'transformer.layer.0.attention.q_lin.weight', 'transformer.layer.0.attention.v_lin.bias', 'transformer.layer.0.attention.v_lin.weight', 'transformer.layer.0.ffn.lin1.bias', 'transformer.layer.0.ffn.lin1.weight', 'transformer.layer.0.ffn.lin2.bias', 'transformer.layer.0.ffn.lin2.weight', 'transformer.layer.0.output_layer_norm.bias', 'transformer.layer.0.output_layer_norm.weight', 'transformer.layer.0.sa_layer_norm.bias', 'transformer.layer.0.sa_layer_norm.weight', 'transformer.layer.1.attention.k_lin.bias', 'transformer.layer.1.attention.k_lin.weight', 'transformer.layer.1.attention.out_lin.bias', 'transformer.layer.1.attention.out_lin.weight', 'transformer.layer.1.attention.q_lin.bias', 'transformer.layer.1.attention.q_lin.weight', 'transformer.layer.1.attention.v_lin.bias', 'transformer.layer.1.attention.v_lin.weight', 'transformer.layer.1.ffn.lin1.bias', 'transformer.layer.1.ffn.lin1.weight', 'transformer.layer.1.ffn.lin2.bias', 'transformer.layer.1.ffn.lin2.weight', 'transformer.layer.1.output_layer_norm.bias', 'transformer.layer.1.output_layer_norm.weight', 'transformer.layer.1.sa_layer_norm.bias', 'transformer.layer.1.sa_layer_norm.weight', 'transformer.layer.10.attention.k_lin.bias', 'transformer.layer.10.attention.k_lin.weight', 'transformer.layer.10.attention.out_lin.bias', 'transformer.layer.10.attention.out_lin.weight', 'transformer.layer.10.attention.q_lin.bias', 'transformer.layer.10.attention.q_lin.weight', 'transformer.layer.10.attention.v_lin.bias', 'transformer.layer.10.attention.v_lin.weight', 'transformer.layer.10.ffn.lin1.bias', 'transformer.layer.10.ffn.lin1.weight', 'transformer.layer.10.ffn.lin2.bias', 'transformer.layer.10.ffn.lin2.weight', 'transformer.layer.10.output_layer_norm.bias', 'transformer.layer.10.output_layer_norm.weight', 'transformer.layer.10.sa_layer_norm.bias', 'transformer.layer.10.sa_layer_norm.weight', 'transformer.layer.11.attention.k_lin.bias', 'transformer.layer.11.attention.k_lin.weight', 'transformer.layer.11.attention.out_lin.bias', 'transformer.layer.11.attention.out_lin.weight', 'transformer.layer.11.attention.q_lin.bias', 'transformer.layer.11.attention.q_lin.weight', 'transformer.layer.11.attention.v_lin.bias', 'transformer.layer.11.attention.v_lin.weight', 'transformer.layer.11.ffn.lin1.bias', 'transformer.layer.11.ffn.lin1.weight', 'transformer.layer.11.ffn.lin2.bias', 'transformer.layer.11.ffn.lin2.weight', 'transformer.layer.11.output_layer_norm.bias', 'transformer.layer.11.output_layer_norm.weight', 'transformer.layer.11.sa_layer_norm.bias', 'transformer.layer.11.sa_layer_norm.weight', 'transformer.layer.2.attention.k_lin.bias', 'transformer.layer.2.attention.k_lin.weight', 'transformer.layer.2.attention.out_lin.bias', 'transformer.layer.2.attention.out_lin.weight', 'transformer.layer.2.attention.q_lin.bias', 'transformer.layer.2.attention.q_lin.weight', 'transformer.layer.2.attention.v_lin.bias', 'transformer.layer.2.attention.v_lin.weight', 'transformer.layer.2.ffn.lin1.bias', 'transformer.layer.2.ffn.lin1.weight', 'transformer.layer.2.ffn.lin2.bias', 'transformer.layer.2.ffn.lin2.weight', 'transformer.layer.2.output_layer_norm.bias', 'transformer.layer.2.output_layer_norm.weight', 'transformer.layer.2.sa_layer_norm.bias', 'transformer.layer.2.sa_layer_norm.weight', 'transformer.layer.3.attention.k_lin.bias', 'transformer.layer.3.attention.k_lin.weight', 'transformer.layer.3.attention.out_lin.bias', 'transformer.layer.3.attention.out_lin.weight', 'transformer.layer.3.attention.q_lin.bias', 'transformer.layer.3.attention.q_lin.weight', 'transformer.layer.3.attention.v_lin.bias', 'transformer.layer.3.attention.v_lin.weight', 'transformer.layer.3.ffn.lin1.bias', 'transformer.layer.3.ffn.lin1.weight', 'transformer.layer.3.ffn.lin2.bias', 'transformer.layer.3.ffn.lin2.weight', 'transformer.layer.3.output_layer_norm.bias', 'transformer.layer.3.output_layer_norm.weight', 'transformer.layer.3.sa_layer_norm.bias', 'transformer.layer.3.sa_layer_norm.weight', 'transformer.layer.4.attention.k_lin.bias', 'transformer.layer.4.attention.k_lin.weight', 'transformer.layer.4.attention.out_lin.bias', 'transformer.layer.4.attention.out_lin.weight', 'transformer.layer.4.attention.q_lin.bias', 'transformer.layer.4.attention.q_lin.weight', 'transformer.layer.4.attention.v_lin.bias', 'transformer.layer.4.attention.v_lin.weight', 'transformer.layer.4.ffn.lin1.bias', 'transformer.layer.4.ffn.lin1.weight', 'transformer.layer.4.ffn.lin2.bias', 'transformer.layer.4.ffn.lin2.weight', 'transformer.layer.4.output_layer_norm.bias', 'transformer.layer.4.output_layer_norm.weight', 'transformer.layer.4.sa_layer_norm.bias', 'transformer.layer.4.sa_layer_norm.weight', 'transformer.layer.5.attention.k_lin.bias', 'transformer.layer.5.attention.k_lin.weight', 'transformer.layer.5.attention.out_lin.bias', 'transformer.layer.5.attention.out_lin.weight', 'transformer.layer.5.attention.q_lin.bias', 'transformer.layer.5.attention.q_lin.weight', 'transformer.layer.5.attention.v_lin.bias', 'transformer.layer.5.attention.v_lin.weight', 'transformer.layer.5.ffn.lin1.bias', 'transformer.layer.5.ffn.lin1.weight', 'transformer.layer.5.ffn.lin2.bias', 'transformer.layer.5.ffn.lin2.weight', 'transformer.layer.5.output_layer_norm.bias', 'transformer.layer.5.output_layer_norm.weight', 'transformer.layer.5.sa_layer_norm.bias', 'transformer.layer.5.sa_layer_norm.weight', 'transformer.layer.6.attention.k_lin.bias', 'transformer.layer.6.attention.k_lin.weight', 'transformer.layer.6.attention.out_lin.bias', 'transformer.layer.6.attention.out_lin.weight', 'transformer.layer.6.attention.q_lin.bias', 'transformer.layer.6.attention.q_lin.weight', 'transformer.layer.6.attention.v_lin.bias', 'transformer.layer.6.attention.v_lin.weight', 'transformer.layer.6.ffn.lin1.bias', 'transformer.layer.6.ffn.lin1.weight', 'transformer.layer.6.ffn.lin2.bias', 'transformer.layer.6.ffn.lin2.weight', 'transformer.layer.6.output_layer_norm.bias', 'transformer.layer.6.output_layer_norm.weight', 'transformer.layer.6.sa_layer_norm.bias', 'transformer.layer.6.sa_layer_norm.weight', 'transformer.layer.7.attention.k_lin.bias', 'transformer.layer.7.attention.k_lin.weight', 'transformer.layer.7.attention.out_lin.bias', 'transformer.layer.7.attention.out_lin.weight', 'transformer.layer.7.attention.q_lin.bias', 'transformer.layer.7.attention.q_lin.weight', 'transformer.layer.7.attention.v_lin.bias', 'transformer.layer.7.attention.v_lin.weight', 'transformer.layer.7.ffn.lin1.bias', 'transformer.layer.7.ffn.lin1.weight', 'transformer.layer.7.ffn.lin2.bias', 'transformer.layer.7.ffn.lin2.weight', 'transformer.layer.7.output_layer_norm.bias', 'transformer.layer.7.output_layer_norm.weight', 'transformer.layer.7.sa_layer_norm.bias', 'transformer.layer.7.sa_layer_norm.weight', 'transformer.layer.8.attention.k_lin.bias', 'transformer.layer.8.attention.k_lin.weight', 'transformer.layer.8.attention.out_lin.bias', 'transformer.layer.8.attention.out_lin.weight', 'transformer.layer.8.attention.q_lin.bias', 'transformer.layer.8.attention.q_lin.weight', 'transformer.layer.8.attention.v_lin.bias', 'transformer.layer.8.attention.v_lin.weight', 'transformer.layer.8.ffn.lin1.bias', 'transformer.layer.8.ffn.lin1.weight', 'transformer.layer.8.ffn.lin2.bias', 'transformer.layer.8.ffn.lin2.weight', 'transformer.layer.8.output_layer_norm.bias', 'transformer.layer.8.output_layer_norm.weight', 'transformer.layer.8.sa_layer_norm.bias', 'transformer.layer.8.sa_layer_norm.weight', 'transformer.layer.9.attention.k_lin.bias', 'transformer.layer.9.attention.k_lin.weight', 'transformer.layer.9.attention.out_lin.bias', 'transformer.layer.9.attention.out_lin.weight', 'transformer.layer.9.attention.q_lin.bias', 'transformer.layer.9.attention.q_lin.weight', 'transformer.layer.9.attention.v_lin.bias', 'transformer.layer.9.attention.v_lin.weight', 'transformer.layer.9.ffn.lin1.bias', 'transformer.layer.9.ffn.lin1.weight', 'transformer.layer.9.ffn.lin2.bias', 'transformer.layer.9.ffn.lin2.weight', 'transformer.layer.9.output_layer_norm.bias', 'transformer.layer.9.output_layer_norm.weight', 'transformer.layer.9.sa_layer_norm.bias', 'transformer.layer.9.sa_layer_norm.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\KIIT0001\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at alexdseo/RecipeBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Ingredients:\n",
      "{\n",
      "  \"ingredients\": [\n",
      "    {\n",
      "      \"name\": \"2 cups all-purpose flour\",\n",
      "      \"amount\": \"\",\n",
      "      \"unit\": \"\",\n",
      "      \"type\": \"dry\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"1.5 cups sugar\",\n",
      "      \"amount\": \"\",\n",
      "      \"unit\": \"\",\n",
      "      \"type\": \"dry\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"3/4 cup milk\",\n",
      "      \"amount\": \"\",\n",
      "      \"unit\": \"\",\n",
      "      \"type\": \"liquid\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"1 tsp vanilla extract\",\n",
      "      \"amount\": \"\",\n",
      "      \"unit\": \"\",\n",
      "      \"type\": \"liquid\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "Failed to parse response, using Gemini's token count API\n",
      "Token usage: 117\n",
      "\n",
      "Converted Measurements:\n",
      "{}\n",
      "\n",
      "Saved to conversions.json\n"
     ]
    }
   ],
   "source": [
    "# BakingLLM - Structured Recipe Conversion System (Fixed Version)\n",
    "import torch\n",
    "from transformers import AutoTokenizer, DistilBertForTokenClassification, pipeline\n",
    "from pydantic import BaseModel\n",
    "from typing import List, Literal\n",
    "import google.generativeai as genai\n",
    "import json\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Configuration\n",
    "load_dotenv()\n",
    "genai.configure(api_key=os.getenv(\"GEMINI_API_KEY\"))\n",
    "gemini_client = genai.GenerativeModel(\"gemini-2.0-flash\")\n",
    "\n",
    "# FoodBERT Model Setup (Search Result 4,7)\n",
    "# FoodBERT Model Setup\n",
    "FOODBERT_CHECKPOINT = \"alexdseo/RecipeBERT\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(FOODBERT_CHECKPOINT)\n",
    "model = DistilBertForTokenClassification.from_pretrained(FOODBERT_CHECKPOINT)\n",
    "\n",
    "\n",
    "# Data Models (Search Result 1)\n",
    "class Ingredient(BaseModel):\n",
    "    name: str\n",
    "    amount: str\n",
    "    unit: str\n",
    "    type: Literal[\"dry\", \"liquid\"]\n",
    "\n",
    "class Recipe(BaseModel):\n",
    "    ingredients: List[Ingredient]\n",
    "\n",
    "# Enhanced Ingredient Type Classifier (Search Result 6)\n",
    "INGREDIENT_TYPE_LOOKUP = {\n",
    "    # Dry ingredients\n",
    "    \"flour\": \"dry\", \"sugar\": \"dry\", \"baking powder\": \"dry\", \"salt\": \"dry\",\n",
    "    # Liquid ingredients\n",
    "    \"milk\": \"liquid\", \"water\": \"liquid\", \"oil\": \"liquid\", \"vanilla\": \"liquid\"\n",
    "}\n",
    "\n",
    "def ingredient_type_lookup(name: str) -> str:\n",
    "    lower_name = name.lower()\n",
    "    return next((v for k, v in INGREDIENT_TYPE_LOOKUP.items() if k in lower_name), \"dry\")\n",
    "\n",
    "# Fixed Extraction Pipeline (Search Result 4,7)\n",
    "def parse_entities(text: str) -> Recipe:\n",
    "    # Use pipeline for feature extraction\n",
    "    extractor = pipeline('feature-extraction', model=FOODBERT_CHECKPOINT, tokenizer=tokenizer)\n",
    "    \n",
    "    # Extract features\n",
    "    features = extractor(text, return_tensors='pt')\n",
    "    \n",
    "    # Process features to extract ingredients (this part needs custom logic)\n",
    "    # For now, let's use a simple splitting approach as a placeholder\n",
    "    ingredients = [ingredient.strip() for ingredient in text.split(',')]\n",
    "    \n",
    "    return Recipe(ingredients=[\n",
    "        Ingredient(\n",
    "            name=ing,\n",
    "            amount=\"\",  # We need more sophisticated parsing for amount and unit\n",
    "            unit=\"\",\n",
    "            type=ingredient_type_lookup(ing)\n",
    "        ) for ing in ingredients\n",
    "    ])\n",
    "\n",
    "# Enhanced Conversion Engine (Search Result 2,5)\n",
    "def convert_measurements(recipe: Recipe) -> dict:\n",
    "    CONVERSION_PROMPT = \"\"\"You are a precision baking measurement converter. \n",
    "    For DRY ingredients (flour, sugar), return weights in grams/ounces.\n",
    "    For LIQUID ingredients (milk, oil), return volumes in milliliters/fluid ounces.\n",
    "    Return ONLY JSON format: {\"ingredient\": {\"original\": \"...\", \"type\": \"...\", \"metric\": \"...\", \"imperial\": \"...\"}}\"\"\"\n",
    "    \n",
    "    ingredients_str = \"\\n\".join(\n",
    "        f\"- {i.amount} {i.unit} {i.name} ({i.type})\" \n",
    "        for i in recipe.ingredients\n",
    "    )\n",
    "    \n",
    "    response = gemini_client.generate_content(\n",
    "        f\"{CONVERSION_PROMPT}\\nConvert these ingredients:\\n{ingredients_str}\"\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        return json.loads(response.text)\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"Failed to parse response, using Gemini's token count API\")  # Search Result 5\n",
    "        usage = gemini_client.count_tokens(CONVERSION_PROMPT + ingredients_str)\n",
    "        print(f\"Token usage: {usage.total_tokens}\")\n",
    "        return {}\n",
    "\n",
    "# Execution Flow with Error Handling\n",
    "if __name__ == \"__main__\":\n",
    "    recipe_text = \"2 cups all-purpose flour, 1.5 cups sugar, 3/4 cup milk, 1 tsp vanilla extract\"\n",
    "    \n",
    "    try:\n",
    "        extracted = parse_entities(recipe_text)\n",
    "        print(\"Extracted Ingredients:\")\n",
    "        print(extracted.model_dump_json(indent=2))\n",
    "        \n",
    "        conversions = convert_measurements(extracted)\n",
    "        print(\"\\nConverted Measurements:\")\n",
    "        print(json.dumps(conversions, indent=2))\n",
    "        \n",
    "        with open(\"conversions.json\", \"w\") as f:\n",
    "            json.dump(conversions, f, indent=2)\n",
    "        print(\"\\nSaved to conversions.json\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "        print(\"Falling back to Gemini extraction\")  # Search Result 1\n",
    "        backup_response = gemini_client.generate_content(f\"Extract ingredients from: {recipe_text}\")\n",
    "        print(backup_response.text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
